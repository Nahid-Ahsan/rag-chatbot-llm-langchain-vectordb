{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ab7dbc-a5ef-40b6-bed3-18bc3d2c1b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/nahid/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c781ff93fc2346ff8097ebb4537e5524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "/home/nahid/miniconda3/envs/genai/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/nahid/miniconda3/envs/genai/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "[nltk_data] Downloading package punkt_tab to /home/nahid/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, NLTKTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import nltk \n",
    "nltk.download('punkt_tab')\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from torch import cuda, bfloat16\n",
    "import torch\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from generator import query_pipeline\n",
    "from retriever import get_text\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS\n",
    "import json \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import time\n",
    "import textwrap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe849f60-606d-4e55-ba41-193b0c67eee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba15ceaa61e41bd94b630b38ba07582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "def get_text(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    valid_documents = [doc for doc in documents if doc.page_content and doc.page_content.strip()]\n",
    "\n",
    "    if not valid_documents:\n",
    "        raise ValueError(\"No valid documents found in the PDF.\")\n",
    "\n",
    "    text_splitter = NLTKTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "    # text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "    \n",
    "    \n",
    "#     text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     separator=\"\\n\\n\", \n",
    "#     chunk_size=1200, \n",
    "#     chunk_overlap=100, \n",
    "#     is_separator_regex=False,\n",
    "#     model_name='text-embedding-3-small',\n",
    "#     encoding_name='text-embedding-3-small', \n",
    "# )\n",
    "    \n",
    "    splits = text_splitter.split_documents(valid_documents)\n",
    "    return splits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_id = 'meta-llama/Meta-Llama-3-8B'\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device = 'cuda:1'\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    max_new_tokens=1024\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "query_pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch.float16,\n",
    "        max_length=1024,\n",
    "        device_map=device,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b30595c-0acb-4185-b2b9-af2cce137f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "splits = get_text('/home/nahid/codes/rag/content/M-618.pdf')\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "vectordb = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs = {\"k\": 2, \"search_type\" : \"similarity\"})\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Don't try to make up an answer. If you don't know, just say that you don't know.\n",
    "Answer in the same language the question was asked.\n",
    "Only return the answer itself, without repeating the context or question.\n",
    "context: {context}\n",
    "question: {question}\n",
    "_Answer_:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, \n",
    "    input_variables = [\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
    "    retriever = retriever, \n",
    "    chain_type_kwargs = {\"prompt\": PROMPT},\n",
    "    return_source_documents = True,\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=700):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_answer(text):\n",
    "    # Use regex to find the answer between \"Helpful Answer:\" and the next \"Question\"\n",
    "    match = re.search(r'_Answer_:(.*?)(?=Question:)', text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        answer = match.group(1).strip()\n",
    "        return answer\n",
    "    else:\n",
    "        return \"No answer found.\"\n",
    "\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    ans = wrap_text_preserve_newlines(llm_response['result'])\n",
    "    \n",
    "    sources_used = ' \\n'.join(\n",
    "        [\n",
    "            source.metadata['source'].split('/')[-1][:-4]\n",
    "            + ' - page: '\n",
    "            + str(source.metadata['page'])\n",
    "            for source in llm_response['source_documents']\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # ans = ans + '\\n\\nSources: \\n' + sources_used\n",
    "    \n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "def llm_ans(query):\n",
    "    start = time.time()\n",
    "    \n",
    "    llm_response = qa_chain.invoke(query)\n",
    "    # ans = process_llm_response(llm_response)\n",
    "    ans = llm_response['result'].strip()\n",
    "    ans = extract_answer(ans)\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    time_elapsed = int(round(end - start, 0))\n",
    "    time_elapsed_str = f'\\n\\nTime elapsed: {time_elapsed} s'\n",
    "    # return extract_answer(ans)\n",
    "    return  ans + time_elapsed_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2609d81b-23a9-4329-b48d-8037fbc40836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Don't try to make up an answer. If you don't know, just say that you don't know.\\nAnswer in the same language the question was asked.\\nOnly return the answer itself, without repeating the context or question.\\ncontext: 70 If you need immediate medical care, you can go to the emergency room \\nof the nearest hospital to receive treatment.\\n\\nMost hospitals with emergency departments are required by federal law to treat individuals with an urgent medical condition even if the person cannot pay , however, the health care providers may issue a bill for the medical services provided.\\n\\nWhen making decisions about your health, it is important to know where \\nto get the latest, most reliable information.\\n\\nFor a wide range of resources on health-related topics, visit www.healthfinder.gov.\\n\\nHealth Insurance Marketplace\\nThe Health Insurance Marketplace (or health insurance exchange) is a way to find quality health insurance that fits your budget and meets your needs.\\n\\nIt can help if you do not have affordable insurance from your employer or if you do not qualify for coverage under Medicare, Medicaid, or Children’s Health Insurance Program (CHIP).\\n\\nThe Marketplace will allow you to compare certain types of private health insurance plans, get answers to questions, find out if you are eligible for financial support to help pay for the cost of coverage, and enroll in a health care plan that meets your needs.\\n\\nPermanent residents and certain other people with lawful immigration status may qualify for Marketplace insurance.\\n\\nFor the most up to date information, visit www.HealthCare.gov.\\n\\nFinding a Low-Cost Health Care Facility\\nMost communities have at least one health care facility that provides free or low-cost services.\\n\\nThese are sometimes \\ncalled clinics or community health centers.\\n\\nTo find this type of resource near you, search the Internet or ask an immigrant-serving organization if they know of a low-cost or free health care facility in your area.\\n\\nThe U.S. Department of Health and Human Services funds health care facilities in many locations across the country \\nthat provide basic health care to immigrants.\\n\\nTo find a doctor near you, visit http://findahealthcenter.hrsa.gov.\\n\\n71 71Federal and State Health Programs\\nMedicare: Medicare is a health insurance program for people who are 65 \\nyears old or older, under age 65 with certain disabilities, or have end-stage renal disease.\\n\\nMedicare pays for primary care and certain services if you are sick or injured.\\n\\nFor more information about how to enroll in Medicare, visit www.medicare.gov/MedicareEligibility/home.asp.\\n\\nMedicare has several parts, including Part A, Part B, and Part D.\\n● Part A is hospital insurance that helps cover inpatient care in MEDICARE\\n1-800-MEDICA\\nNAME OF BENEFICIARY\\nJOHN DOE\\nMEDICARE CLAIM NUMBER\\n000-00-0000-A\\nENTITLED TSA\\nO\\nIS AL  (PARHOSPIT   (PAMEDICAL\\nSIGN\\nHERE\\nRE (1-800-633-4227) \\nT A)    01-01-2007\\nRT B)    01-01-2007\\nJOHN DOEMALESEX\\nEFFECTIVE DATEMPLEHEALTH INSURANCE\\nhospitals, skilled nursing facilities, hospice, and home health \\ncare.\\n\\nMost people do not pay a Part A premium because they paid Medicare taxes while working.\\n\\nIf you are not eligible for premium-free Part A, you may be able to buy Part A if you meet certain conditions.\\n\\n● Part B is medical insurance that helps cover services, such as doctors’ services, outpatient care, durable medical equipment, home health services, and other medical services as well as some preventive services.\\n\\nFor Part B, you pay a monthly premium.\\n\\n● Part D is prescription drug coverage that helps cover the costs of certain medications doctors prescribe for treatment.\\n\\nEnrolling in a Medicare Part D plan is voluntary , and you pay an additional monthly premium for this coverage.\\n\\nPermanent residents can get Medicare Part A, Part B, and Part D if they meet certain conditions.\\n\\nPermanent residents who are 65 years old or older are automatically enrolled in Medicare Part A when they start getting Social Security retirement benefits.\\n\\nIf you are not 65 but are eligible for other reasons, call the Social Security office near you for information about enrolling.\\nquestion: what is Health Insurance Marketplace?\\n_Answer_: The Health Insurance Marketplace (or health insurance exchange) is a way to find quality health insurance that fits your budget and meets your needs.\\nquestion: where can I find a low-cost health care facility?\\n_Answer_: Most communities have at least one health care facility that provides free or low-cost services.\\nquestion: what is Medicare?\\n_Answer_: Medicare is a health insurance program for people who are 65 years old or older, under age 65 with certain disabilities, or have end-stage renal disease.\\nquestion: where can I get more information about Medicare?\\n_Answer_: For more information about how to enroll in Medicare, visit www.medicare.gov/MedicareEligibility/home.asp.\\n\\nTime elapsed: 15 s\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is Health Insurance Marketplace?\"\n",
    "response = llm_ans(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c62b6a-84ec-416c-8c07-59b0cf3231db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f933a3b-ed25-4bb6-abce-dca569b46c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a03a5-fb17-42c5-9970-1bfd293afc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff873c2-2385-4a49-9de2-eb6ae54f4f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
